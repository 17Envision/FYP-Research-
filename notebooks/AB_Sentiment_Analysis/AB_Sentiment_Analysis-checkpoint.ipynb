{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93b8ce1-9ccb-43ce-8fa8-a063323225ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langid.langid import LanguageIdentifier, model\n",
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import re\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d5cab92-154a-4c91-9f30-03f18beaf15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Comment Id              User Id           Unique Id    Nickname  \\\n",
      "0  7221188022045099008  7163539283471025152        kawigamage23   කවී ගමගේ   \n",
      "1  7221178613064123392  6924965585139237888            mruzi135      Uziiii   \n",
      "2  7221176459355882496  6863443316852704256           ashiixxx1    එරන්දි🌸💕   \n",
      "3  7333542921793094656  7004024870121554944           udmusic01  •ᴜᴅ ᴍᴜꜱɪᴄ•   \n",
      "4  7221231966270751744  6926885343124636672  dinushamadushani81        Dinu   \n",
      "\n",
      "                                              Avatar  \\\n",
      "0  https://p16-sign-sg.tiktokcdn.com/aweme/100x10...   \n",
      "1  https://p16-sign-useast2a.tiktokcdn.com/tos-us...   \n",
      "2  https://p16-sign-useast2a.tiktokcdn.com/tos-us...   \n",
      "3  https://p16-sign-useast2a.tiktokcdn.com/tos-us...   \n",
      "4  https://p16-sign-sg.tiktokcdn.com/aweme/100x10...   \n",
      "\n",
      "                                     User URL  Reply Comment Id  \\\n",
      "0        https://www.tiktok.com/@kawigamage23                 0   \n",
      "1            https://www.tiktok.com/@mruzi135                 0   \n",
      "2           https://www.tiktok.com/@ashiixxx1                 0   \n",
      "3           https://www.tiktok.com/@udmusic01                 0   \n",
      "4  https://www.tiktok.com/@dinushamadushani81                 0   \n",
      "\n",
      "                              Comment  Digg Count  Reply Count  \\\n",
      "0                       rashmika wage         412         13.0   \n",
      "1                    rashmika wge ade           7          1.0   \n",
      "2                               සාරංග         687          8.0   \n",
      "3               ඉස්සරහට නිලියක් ශුවර්          22          1.0   \n",
      "4  rashmika mathk una..eya wage tikak         128          2.0   \n",
      "\n",
      "   Is Author Digged  Author Pin Language          Create Time  \\\n",
      "0             False         0.0       en  2023-04-12 21:07:57   \n",
      "1             False         0.0       id  2023-04-12 20:31:20   \n",
      "2             False         0.0       si  2023-04-12 20:22:59   \n",
      "3             False         0.0       si  2024-02-09 15:42:21   \n",
      "4             False         0.0       en  2023-04-12 23:58:25   \n",
      "\n",
      "                                           Video URL             Video Id  \n",
      "0  https://www.tiktok.com/@hirutv/video/722117384...  7221173843384224768  \n",
      "1  https://www.tiktok.com/@hirutv/video/722117384...  7221173843384224768  \n",
      "2  https://www.tiktok.com/@hirutv/video/722117384...  7221173843384224768  \n",
      "3  https://www.tiktok.com/@hirutv/video/722117384...  7221173843384224768  \n",
      "4  https://www.tiktok.com/@hirutv/video/722117384...  7221173843384224768  \n"
     ]
    }
   ],
   "source": [
    "# Detect encoding\n",
    "with open(\"comments_no_any_emoji.xlsx\", 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    encoding = result['encoding']\n",
    "\n",
    "# Read the file with the detected encoding\n",
    "df = pd.read_excel(\"comments_no_any_emoji.xlsx\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273343ea-8d12-420f-94e1-77d30efd82a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: filelock in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (3.13.3)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (15.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (0.22.1)\n",
      "Requirement already satisfied: packaging in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\uom\\l4s1\\research\\implementation\\fyp-research\\env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d012194-7392-4b87-8124-66ec7aad2c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3d0a693cc244cc8b84c2fe0a4a9408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 293M/293M [02:19<00:00, 2.10MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b6618553441deab7ff7e8b6c25c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# hugging face model 1\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"deshanksuman/Swabhasha_RomanizedSinhala_Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db315ec-3205-4fff-abb6-09aaa894d850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the first ten items of the dataset and print each row\n",
    "for example in dataset[\"train\"][:10]:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6978158-15c0-4160-88de-a5e99ce2f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yogyathama/යෝග්‍යතම\n",
      "yogyatha/යෝග්‍යතා\n",
      "yogya/යෝග්‍ය\n",
      "yogini/යෝගිනී\n",
      "yoghurt/යෝගට්\n",
      "yoghat/යෝගට්\n",
      "yogee/යෝගී\n",
      "yogayehi/යෝගයෙහි\n",
      "yogaya/යෝගය\n",
      "yogat/යෝගට්\n"
     ]
    }
   ],
   "source": [
    "# Specify the path to the text file\n",
    "input_text_file = \"../../data/singlishtrainsuggest.txt\"\n",
    "\n",
    "# Open the text file in read mode\n",
    "with open(input_text_file, \"r\", encoding=\"utf-8\") as text_file:\n",
    "    # Read all lines from the text file\n",
    "    lines = text_file.readlines()\n",
    "\n",
    "# Print the first 10 lines\n",
    "for line in lines[:10]:\n",
    "    print(line.strip())  # Remove leading/trailing whitespace and print\n",
    "\n",
    "# You can further process the lines as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35040fd9-542e-4461-b233-4aa438bcffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
